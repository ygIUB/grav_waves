{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c062f4cf-1945-4aa2-8a89-3fe25f2c64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5030aba2-e4bc-431d-a88b-5e76b4c3a4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-12 17:57:59--  https://www.codabench.org/datasets/download/e703ab84-4444-4972-9ef7-1ebd0fc09c88/\n",
      "Resolving www.codabench.org (www.codabench.org)... 129.175.8.21\n",
      "Connecting to www.codabench.org (www.codabench.org)|129.175.8.21|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://miniodis-rproxy.lisn.upsaclay.fr/coda-v2-prod-private/dataset/2024-04-10-1712755618/1df8aa91cfc4/Datasets.zip?AWSAccessKeyId=EASNOMJFX9QFW4QIY4SL&Signature=HNsGQ%2FBqixg02M6lIrYLKMHEP%2BQ%3D&Expires=1737136379 [following]\n",
      "--2025-01-12 17:58:00--  https://miniodis-rproxy.lisn.upsaclay.fr/coda-v2-prod-private/dataset/2024-04-10-1712755618/1df8aa91cfc4/Datasets.zip?AWSAccessKeyId=EASNOMJFX9QFW4QIY4SL&Signature=HNsGQ%2FBqixg02M6lIrYLKMHEP%2BQ%3D&Expires=1737136379\n",
      "Resolving miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)... 129.175.8.29\n",
      "Connecting to miniodis-rproxy.lisn.upsaclay.fr (miniodis-rproxy.lisn.upsaclay.fr)|129.175.8.29|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 496248480 (473M) [application/zip]\n",
      "Saving to: ‘public_data.zip’\n",
      "\n",
      "public_data.zip     100%[===================>] 473.26M  19.6MB/s    in 32s     \n",
      "\n",
      "2025-01-12 17:58:34 (14.7 MB/s) - ‘public_data.zip’ saved [496248480/496248480]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O public_data.zip https://www.codabench.org/datasets/download/e703ab84-4444-4972-9ef7-1ebd0fc09c88/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc9e16f-96fc-4ba0-9454-020cbad2641f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archive:  public_data.zip',\n",
       " 'replace files/sglf_for_challenge.npy? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n",
       " '(EOF or read error, treating as \"[N]one\" ...)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!unzip public_data.zip -d files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f6a89-9993-4fd2-a5d3-3698091ea29a",
   "metadata": {},
   "source": [
    "Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af7b76b2-b387-4a2d-b11e-658089e050d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train/test shapes: (80000, 200, 2) (20000, 200, 2)\n",
      "y train/test shapes: (80000, 200, 2) (20000, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data and normalize it\n",
    "background = np.load('files/background.npz')['data']\n",
    "stds = np.std(background, axis=-1)[:, :, np.newaxis]\n",
    "background = background/stds\n",
    "background = np.swapaxes(background, 1, 2)\n",
    "\n",
    "bbh = np.load('files/bbh_for_challenge.npy')\n",
    "stds = np.std(bbh, axis=-1)[:, :, np.newaxis]\n",
    "bbh = bbh/stds\n",
    "bbh = np.swapaxes(bbh, 1, 2)\n",
    "\n",
    "sglf = np.load('files/sglf_for_challenge.npy')\n",
    "stds = np.std(sglf, axis=-1)[:, :, np.newaxis]\n",
    "sglf = sglf/stds\n",
    "sglf = np.swapaxes(sglf, 1, 2)\n",
    "\n",
    "# Create train and test datasets\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     background, background, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train/test shapes: {x_train.shape} {x_test.shape}')\n",
    "print(f'y train/test shapes: {y_train.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97be51c1-d6f4-4463-be85-09228841e732",
   "metadata": {},
   "source": [
    "Create the VAE model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "498bc4ed-45d2-4d50-812b-1cbb0be36f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder layer shape is (None, 200, 2)\n",
      "Encoder layer shape is (None, 200, 2)\n",
      "Encoder layer shape is (None, 200, 2)\n",
      "Encoder layer shape is (None, 200, 2)\n",
      "Latent space shape is (None, 400)\n",
      "z_mean: (None, 16)\n",
      "z_log_var: (None, 16)\n",
      "sampling layer: <Sampling name=sampling_21, built=False>\n",
      "Decoder layer shape is (None, 200, 2)\n",
      "Decoder layer shape is (None, 200, 2)\n",
      "Decoder layer shape is (None, 200, 2)\n",
      "Decoder layer shape is (None, 200, 2)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 200\u001b[0m\n\u001b[1;32m    189\u001b[0m vae \u001b[38;5;241m=\u001b[39m VAE()\n\u001b[1;32m    190\u001b[0m vae \u001b[38;5;241m=\u001b[39m vae\u001b[38;5;241m.\u001b[39mbuild_model(\n\u001b[1;32m    191\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39mx_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    192\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    198\u001b[0m )\n\u001b[0;32m--> 200\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(\n\u001b[1;32m    201\u001b[0m     x_train,\n\u001b[1;32m    202\u001b[0m     validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m    203\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m    204\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m    205\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)],\n\u001b[1;32m    206\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        mean, log_var = inputs\n",
    "        batch = tf.shape(mean)[0]\n",
    "        dim = tf.shape(mean)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return mean + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "\n",
    "class MSELossLayer(layers.Layer):\n",
    "    \"\"\"Custom layer to calculate MSE loss.\"\"\"\n",
    "    def call(self, inputs):\n",
    "        y_true, y_pred = inputs\n",
    "        loss = tf.keras.losses.mse(y_true, y_pred)\n",
    "        # Change the axis to (1,) to sum over the sequence dimension\n",
    "        return tf.reduce_sum(loss, axis=(1,))  # Sum over sequence\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        x = layers.MultiHeadAttention(\n",
    "            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(inputs, inputs)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        return x + res\n",
    "\n",
    "    def dense_decoder(self, inputs, ff_dim, output_dim, dropout=0):\n",
    "        # Flatten the input to apply dense layers\n",
    "        x = layers.Flatten()(inputs)\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = layers.Dense(ff_dim)(x)  # Align dimensions for residual\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = x + res\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Dense(np.prod(inputs.shape[1:]))(x)  # Output dimension should match the flattened input dimension\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Reshape back to original input shape\n",
    "        x = layers.Reshape(inputs.shape[1:])(x)\n",
    "        return x + inputs  # Adding input directly, assuming output_dim matches inputs shape[-1]\n",
    "\n",
    "    def build_model(self, input_shape, latent_dim, head_size, num_heads, ff_dim, num_transformer_blocks, dropout=0.1):\n",
    "        # Encoder\n",
    "        inputs = layers.Input(shape=input_shape, name=\"encoder_input\")\n",
    "        x = inputs\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "            print(\"Encoder layer shape is \" + str(x.shape))\n",
    "\n",
    "        # Flatten for latent space\n",
    "        x = layers.Flatten()(x)  # Shape: (None, 200 * 2)\n",
    "\n",
    "        # Latent space\n",
    "        print(\"Latent space shape is \" + str(x.shape))\n",
    "        \n",
    "        z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "        print(\"z_mean: \" + str(z_mean.shape))\n",
    "        z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "        print(\"z_log_var: \" + str(z_log_var.shape))\n",
    "\n",
    "        #Sampling layer\n",
    "        sampling_layer = Sampling()\n",
    "        print(\"sampling layer: \" + str(sampling_layer))\n",
    "        z = sampling_layer([z_mean, z_log_var])\n",
    "        \n",
    "        # Decoder\n",
    "        latent_inputs = layers.Input(shape=(latent_dim,), name=\"z_sampling\")\n",
    "        x = layers.Dense(np.prod(input_shape), activation=\"relu\")(latent_inputs)\n",
    "        x = layers.Reshape(input_shape)(x)\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.dense_decoder(x, ff_dim, input_shape[-1], dropout)\n",
    "            print(\"Decoder layer shape is \" + str(x.shape))\n",
    "        outputs = layers.Dense(input_shape[-1])(x)\n",
    "\n",
    "        # Build models\n",
    "        self.encoder = models.Model(inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "        self.decoder = models.Model(latent_inputs, outputs, name=\"decoder\")\n",
    "        reconstructed = self.decoder(z)\n",
    "\n",
    "        self.vae = models.Model(inputs, reconstructed, name=\"vae\")\n",
    "        self.vae.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "      def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Pass data through encoder\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "\n",
    "            # Reconstruct data from latent space\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # Calculate reconstruction loss (Mean Squared Error for continuous data)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            # Calculate KL divergence\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "            )\n",
    "\n",
    "            # Total loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        # Apply gradients\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        # Update custom metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        # Return metrics\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # For evaluation, calculate losses without updating weights\n",
    "        z_mean, z_log_var, z = self.encoder(data)\n",
    "        reconstruction = self.decoder(z)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.keras.losses.mean_squared_error(data, reconstruction), axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "        )\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "\n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        # List all metrics for reset and display\n",
    "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
    "    def fit(self, x_train, **kwargs):\n",
    "        history = self.vae.fit(x_train, x_train, **kwargs)\n",
    "        return history\n",
    "\n",
    "    def save(self, path):\n",
    "        self.encoder.save(path + \"_encoder.keras\")\n",
    "        self.decoder.save(path + \"_decoder.keras\")\n",
    "        self.vae.save(path + \"_vae.keras\")\n",
    "\n",
    "    def load(self, path):\n",
    "        self.encoder = models.load_model(path + \"_encoder.keras\", custom_objects={\"Sampling\": Sampling})\n",
    "        self.decoder = models.load_model(path + \"_decoder.keras\")\n",
    "        self.vae = models.load_model(path + \"_vae.keras\", custom_objects={\"Sampling\": Sampling})\n",
    "\n",
    "    def predict(self, X, batch_size=32):\n",
    "        return self.vae.predict(X, batch_size=batch_size)\n",
    "\n",
    "vae = VAE()\n",
    "vae = vae.build_model(\n",
    "    input_shape=x_train.shape[1:],\n",
    "    latent_dim=16,\n",
    "    head_size=64,\n",
    "    num_heads=8,\n",
    "    ff_dim=128,\n",
    "    num_transformer_blocks=4,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "history = vae.fit(\n",
    "    x_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424887b-3564-48f9-9787-efa7d70e6dc5",
   "metadata": {},
   "source": [
    "ATTEMPT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc87323f-3bc8-437e-8cc8-f76f63f7c40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ebbbb-f8b4-4eaf-804b-caa9e11b387c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
